/*
Copyright 2019 The Knative Authors

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// The make_config tool generates a full Prow config for the Knative project,
// with input from a yaml file with key definitions.

package main

import (
	"bytes"
	"flag"
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"text/template"
	"time"

	"gopkg.in/yaml.v2"
)

const (
	// Manifests generated by ko are indented by 2 spaces.
	baseIndent = "  "
	// Cron strings for key jobs
	goCoveragePeriodicJobCron     = "0 1 * * *"  // Run at 01:00 every day
	cleanupPeriodicJobCron        = "0 19 * * 1" // Run at 11:00PST/12:00PST every Monday (19:00 UTC)
	flakesReporterPeriodicJobCron = "0 12 * * *" // Run at 4:00PST/5:00PST every day (12:00 UTC)
	backupPeriodicJobCron         = "15 9 * * *" // Run at 02:15PST every day (09:15 UTC)

	// baseOptions setting for testgrid dashboard tabs
	testgridTabGroupByDir    = "exclude-filter-by-regex=Overall$&group-by-directory=&expand-groups=&sort-by-name="
	testgridTabGroupByTarget = "exclude-filter-by-regex=Overall$&group-by-target=&expand-groups=&sort-by-name="
	testgridTabSortByName    = "sort-by-name="
)

// repositoryData contains basic data about each Knative repository.
type repositoryData struct {
	Name                string
	EnableGoCoverage    bool
	GoCoverageThreshold int
	Processed           bool
}

// baseProwJobTemplateData contains basic data about a Prow job.
type baseProwJobTemplateData struct {
	RepoName            string
	RepoNameForJob      string
	GcsBucket           string
	GcsLogDir           string
	GcsPresubmitLogDir  string
	RepoURI             string
	RepoBranch          string
	CloneURI            string
	SecurityContext     []string
	SkipBranches        []string
	DecorationConfig    []string
	ExtraRefs           []string
	Command             string
	Args                []string
	Env                 []string
	Volumes             []string
	VolumeMounts        []string
	Timeout             int
	AlwaysRun           bool
	LogsDir             string
	PresubmitLogsDir    string
	TestAccount         string
	ServiceAccount      string
	ReleaseGcs          string
	GoCoverageThreshold int
	Image               string
	Year                int
}

// ####################################################################################################
// ################ data definitions that are used for the prow config file generation ################
// ####################################################################################################
// presubmitJobTemplateData contains data about a presubmit Prow job.
type presubmitJobTemplateData struct {
	Base                 baseProwJobTemplateData
	PresubmitJobName     string
	PresubmitPullJobName string
	PresubmitPostJobName string
	PresubmitCommand     []string
}

// periodicJobTemplateData contains data about a periodic Prow job.
type periodicJobTemplateData struct {
	Base            baseProwJobTemplateData
	PeriodicJobName string
	CronString      string
	PeriodicCommand []string
}

// postsubmitJobTemplateData contains data about a postsubmit Prow job.
type postsubmitJobTemplateData struct {
	Base              baseProwJobTemplateData
	PostsubmitJobName string
}

// sectionGenerator is a function that generates Prow job configs given a slice of a yaml file with configs.
type sectionGenerator func(string, string, yaml.MapSlice)

// newJobNeeded is a function that determined if we need to add a new job for this repository.
type newJobNeeded func(repositoryData) bool

// stringArrayFlag is the content of a multi-value flag.
type stringArrayFlag []string

// ####################################################################################################
// ############## data definitions that are used for the testgrid config file generation ##############
// ####################################################################################################
// baseTestgridTemplateData contains basic data about the testgrid config file.
// TODO(Fredy-Z): remove this structure and use baseProwJobTemplateData instead
type baseTestgridTemplateData struct {
	TestGroupName string
	Year          int
}

// testGroupTemplateData contains data about a test group
type testGroupTemplateData struct {
	Base baseTestgridTemplateData
	// TODO(Fredy-Z): use baseProwJobTemplateData then this attribute can be removed
	GcsLogDir string
	Extras    map[string]string
}

// dashboardTabTemplateData contains data about a dashboard tab
type dashboardTabTemplateData struct {
	Base        baseTestgridTemplateData
	Name        string
	BaseOptions string
	Extras      map[string]string
}

// dashboardGroupTemplateData contains data about a dashboard group
type dashboardGroupTemplateData struct {
	Name      string
	RepoNames []string
}

// testgridEntityGenerator is a function that generates the entity given the repo name and job names
type testgridEntityGenerator func(string, []string)

var (
	// Values used in the jobs that can be changed through command-line flags.
	output                    *os.File
	gcsBucket                 string
	logsDir                   string
	presubmitLogsDir          string
	testAccount               string
	nightlyAccount            string
	releaseAccount            string
	flakesreporterDockerImage string
	coverageDockerImage       string
	prowTestsDockerImage      string
	presubmitScript           string
	releaseScript             string
	performanceScript         string
	webhookAPICoverageScript  string
	cleanupScript             string

	// #########################################################################
	// ############## data used for generating prow configuration ##############
	// #########################################################################
	// Array constants used throughout the jobs.
	allPresubmitTests = []string{"--all-tests", "--emit-metrics"}
	releaseNightly    = []string{"--publish", "--tag-release"}
	releaseLocal      = []string{"--nopublish", "--notag-release"}

	// Overrides and behavior changes through command-line flags.
	repositoryOverride string
	jobNameFilter      string
	preCommand         string
	extraEnvVars       stringArrayFlag
	timeoutOverride    int

	// List of Knative repositories.
	repositories []repositoryData

	// Map which sections of the config.yaml were written to stdout.
	sectionMap map[string]bool

	// #############################################################################
	// ############## data used for generating testgrid configuration ##############
	// #############################################################################
	// goCoverageMap keep track of which repo has go code coverage when parsing the simple config file
	goCoverageMap map[string]bool
	// projNames save the proj names in a list when parsing the simple config file, for the purpose of maintaining the output sequence
	projNames []string
	// repoNames save the repo names in a list when parsing the simple config file, for the purpose of maintaining the output sequence
	repoNames []string

	// metaData saves the meta data needed to generate the final config file
	// key is the main project version, value is another map containing job details
	//     for the job detail map, key is the repo name, value is the list of job types, like continuous, latency, nightly, and etc.
	metaData = make(map[string]map[string][]string)
)

// Templates for config generation.

const (
	// ##########################################################
	// ############## prow configuration templates ##############
	// ##########################################################
	// generalProwConfig contains config-wide definitions.
	generalProwConfig = `
# Copyright [[.Year]] The Knative Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# ############################################################
# ####                                                    ####
# #### THIS FILE IS AUTOMATICALLY GENERATED. DO NOT EDIT. ####
# ####     USE "make config" TO REGENERATE THIS FILE.     ####
# ####                                                    ####
# ############################################################

plank:
  job_url_template: 'https://gubernator.knative.dev/build/[[.GcsBucket]]/{{if or (eq .Spec.Type "presubmit") (eq .Spec.Type "batch")}}[[.PresubmitLogsDir]]/pull{{with .Spec.Refs}}/{{.Org}}_{{.Repo}}{{end}}{{else}}[[.LogsDir]]{{end}}{{if eq .Spec.Type "presubmit"}}/{{with index .Spec.Refs.Pulls 0}}{{.Number}}{{end}}{{else if eq .Spec.Type "batch"}}/batch{{end}}/{{.Spec.Job}}/{{.Status.BuildID}}/'
  report_template: '[Full PR test history](https://gubernator.knative.dev/pr/{{.Spec.Refs.Org}}_{{.Spec.Refs.Repo}}/{{with index .Spec.Refs.Pulls 0}}{{.Number}}{{end}}). [Your PR dashboard](https://gubernator.knative.dev/pr/{{with index .Spec.Refs.Pulls 0}}{{.Author}}{{end}}).'
  pod_pending_timeout: 60m
  default_decoration_config:
    timeout: 7200000000000 # 2h
    grace_period: 15000000000 # 15s
    utility_images:
      # Update these versions when updating plank version in cluster.yaml
      clonerefs: "gcr.io/k8s-prow/clonerefs:v20190517-bb7028b16"
      initupload: "gcr.io/k8s-prow/initupload:v20190517-bb7028b16"
      entrypoint: "gcr.io/k8s-prow/entrypoint:v20190517-bb7028b16"
      sidecar: "gcr.io/k8s-prow/sidecar:v20190517-bb7028b16"
    gcs_configuration:
      bucket: "[[.GcsBucket]]"
      path_strategy: "explicit"
    gcs_credentials_secret: "test-account"

prowjob_namespace: default
pod_namespace: test-pods
log_level: debug

branch-protection:
  orgs:
    knative:
      # Protect all branches in knative
      # This means all prow jobs with "always_run" set are required
      # to pass before tide can merge the PR.
      # Currently this is manually enabled by the knative org admins,
      # but it's stated here for documentation and reference purposes.
      protect: true
      # Admins can overrule checks
      enforce_admins: false

tide:
  queries:
  - repos:
    - knative/build
    - knative/build-templates
    - knative/client
    - knative/observability
    - knative/serving
    - knative/eventing
    - knative/eventing-sources
    - knative/docs
    - knative/test-infra
    - knative/pkg
    - knative/caching
    - knative/website
    - knative/community
    labels:
    - lgtm
    - approved
    missingLabels:
    - do-not-merge/hold
    - do-not-merge/work-in-progress
    - do-not-merge/invalid-owners-file
  merge_method:
    knative: squash
  target_url: https://prow.knative.dev/tide
  pr_status_base_url: https://prow.knative.dev/pr
  blocker_label: tide/merge-blocker
  squash_label: tide/merge-method-squash
  rebase_label: tide/merge-method-rebase
  merge_label: tide/merge-method-merge
`

	// presubmitJob is the template for presubmit jobs.
	presubmitJob = `
  - name: [[.PresubmitPullJobName]]
    agent: kubernetes
    context: [[.PresubmitPullJobName]]
    always_run: [[.Base.AlwaysRun]]
    rerun_command: "/test [[.PresubmitPullJobName]]"
    trigger: "(?m)^/test (all|[[.PresubmitPullJobName]]),?(\\s+|$)"
    [[indent_array_section 4 "skip_branches" .Base.SkipBranches]]
    spec:
      containers:
      - image: [[.Base.Image]]
        imagePullPolicy: Always
        args:
        - "--scenario=kubernetes_execute_bazel"
        - "--clean"
        - "--job=$(JOB_NAME)"
        - "--repo=github.com/$(REPO_OWNER)/$(REPO_NAME)=$(PULL_REFS)"
        - "--root=/go/src"
        - "--service-account=[[.Base.ServiceAccount]]"
        - "--upload=[[.Base.GcsPresubmitLogDir]]"
        - "--" # end bootstrap args, scenario args below
        - "--" # end kubernetes_execute_bazel flags (consider following flags as text)
        [[indent_array 8 .PresubmitCommand]]
        [[indent_section 10 "securityContext" .Base.SecurityContext]]
        [[indent_section 8 "volumeMounts" .Base.VolumeMounts]]
        [[indent_section 8 "env" .Base.Env]]
      [[indent_section 6 "volumes" .Base.Volumes]]
`

	// presubmitGoCoverageJob is the template for go coverage presubmit jobs.
	presubmitGoCoverageJob = `
  - name: [[.PresubmitPullJobName]]
    agent: kubernetes
    context: [[.PresubmitPullJobName]]
    always_run: [[.Base.AlwaysRun]]
    rerun_command: "/test [[.PresubmitPullJobName]]"
    trigger: "(?m)^/test (all|[[.PresubmitPullJobName]]),?(\\s+|$)"
    optional: true
    decorate: true
    clone_uri: [[.Base.CloneURI]]
    spec:
      containers:
      - image: [[.Base.Image]]
        imagePullPolicy: Always
        command:
        - "/coverage"
        args:
        - "--postsubmit-job-name=[[.PresubmitPostJobName]]"
        - "--artifacts=$(ARTIFACTS)"
        - "--cov-threshold-percentage=[[.Base.GoCoverageThreshold]]"
        - "--github-token=/etc/covbot-token/token"
        [[indent_section 8 "volumeMounts" .Base.VolumeMounts]]
        [[indent_section 8 "env" .Base.Env]]
      [[indent_section 6 "volumes" .Base.Volumes]]
`

	// periodicTestJob is the template for periodic test/release jobs.
	periodicTestJob = `
- cron: "[[.CronString]]"
  name: [[.PeriodicJobName]]
  agent: kubernetes
  spec:
    containers:
    - image: [[.Base.Image]]
      imagePullPolicy: Always
      args:
      - "--scenario=kubernetes_execute_bazel"
      - "--clean"
      - "--job=$(JOB_NAME)"
      - "--repo=[[repo .Base]]"
      - "--root=/go/src"
      - "--service-account=[[.Base.ServiceAccount]]"
      - "--upload=[[.Base.GcsLogDir]]"
      - "--timeout=[[.Base.Timeout]]" # Avoid overrun
      - "--" # end bootstrap args, scenario args below
      - "--" # end kubernetes_execute_bazel flags (consider following flags as text)
      [[indent_array 6 .PeriodicCommand]]
      [[indent_section 8 "securityContext" .Base.SecurityContext]]
      [[indent_section 6 "volumeMounts" .Base.VolumeMounts]]
      [[indent_section 6 "env" .Base.Env]]
    [[indent_section 4 "volumes" .Base.Volumes]]
`

	// periodicCustomJob is the template for periodic custom jobs.
	periodicCustomJob = `
- cron: "[[.CronString]]"
  name: [[.PeriodicJobName]]
  agent: kubernetes
  decorate: true
  [[indent_section 4 "decoration_config" .Base.DecorationConfig]]
  [[indent_section 2 "extra_refs" .Base.ExtraRefs]]
  spec:
    containers:
    - image: [[.Base.Image]]
      imagePullPolicy: Always
      command:
      - "[[.Base.Command]]"
      [[indent_array_section 6 "args" .Base.Args]]
      [[indent_section 6 "volumeMounts" .Base.VolumeMounts]]
      [[indent_section 6 "env" .Base.Env]]
    [[indent_section 4 "volumes" .Base.Volumes]]
`

	// goCoveragePostsubmitJob is the template for the go postsubmit coverage job.
	goCoveragePostsubmitJob = `
  - name: [[.PostsubmitJobName]]
    branches:
    - master
    agent: kubernetes
    decorate: true
    clone_uri: [[.Base.CloneURI]]
    spec:
      containers:
      - image: [[.Base.Image]]
        imagePullPolicy: Always
        command:
        - "/coverage"
        args:
        - "--artifacts=$(ARTIFACTS)"
        - "--cov-threshold-percentage=0"
`

	// ##############################################################
	// ############## testgrid configuration templates ##############
	// ##############################################################

	// generalTestgridConfig contains config-wide definitions.
	generalTestgridConfig = `
# Copyright [[.Year]] The Knative Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# ############################################################
# ####                                                    ####
# #### THIS FILE IS AUTOMATICALLY GENERATED. DO NOT EDIT. ####
# ####     USE "make config" TO REGENERATE THIS FILE.     ####
# ####                                                    ####
# ############################################################

# Default testgroup and dashboardtab, please do not change them
default_test_group:
  days_of_results: 14            # Number of days of test results to gather and serve
  tests_name_policy: 2           # Replace the name of the test
  ignore_pending: false          # Show in-progress tests
  column_header:
  - configuration_value: Commit  # Shows the commit number on column header
  - configuration_value: infra-commit
  num_columns_recent: 10         # The number of columns to consider "recent" for a variety of purposes
  use_kubernetes_client: true    # ** This field is deprecated and should always be true **
  is_external: true              # ** This field is deprecated and should always be true **
  alert_stale_results_hours: 26  # Alert if tests haven't run for a day (1 day + 2h)
  num_failures_to_alert: 1       # Alert for every failure
  num_passes_to_disable_alert: 1 # Consider a failing test passing if it has 1 or more consecutive passes

default_dashboard_tab:
  open_test_template:            # The URL template to visit after clicking on a cell
    url: https://gubernator.knative.dev/build/<gcs_prefix>/<changelist>
  file_bug_template:             # The URL template to visit when filing a bug
    url: https://github.com/knative/serving/issues/new
    options:
    - key: title
      value: "Test \"<test-name>\" failed"
    - key: body
      value: <test-url>
  attach_bug_template:           # The URL template to visit when attaching a bug
    url:                         # Empty
    options:                     # Empty
  # Text to show in the about menu as a link to another view of the results
  results_text: See these results in Gubernator
  results_url_template:          # The URL template to visit after clicking
    url: https://gubernator.knative.dev/builds/<gcs_prefix>
  # URL for regression search links.
  code_search_path: github.com/knative/serving/search
  num_columns_recent: 10
  code_search_url_template:      # The URL template to visit when searching for changelists
    url: https://github.com/knative/serving/compare/<start-custom-0>...<end-custom-0>
  alert_options:
    alert_mail_to_addresses: "knative-productivity-dev@googlegroups.com"
	`

	// testGroupTemplate is the template for the test group config
	testGroupTemplate = `
- name: [[.Base.TestGroupName]]
  gcs_prefix: [[.GcsLogDir]]
  [[indent_map 2 .Extras]]
	`

	// dashboardTabTemplate is the template for the dashboard tab config
	dashboardTabTemplate = `
  - name: [[.Name]]
    test_group_name: [[.Base.TestGroupName]]
    base_options: "[[.BaseOptions]]"
    [[indent_map 2 .Extras]]
	`

	// dashboardGroupTemplate is the template for the dashboard tab config
	dashboardGroupTemplate = `
- name: [[.Name]]
  dashboard_names:
  [[indent_array 2 .RepoNames]]
	`
)

// Yaml parsing helpers.

// getString casts the given interface (expected string) as string.
// An array of length 1 is also considered a single string.
func getString(s interface{}) string {
	if _, ok := s.([]interface{}); ok {
		values := getStringArray(s)
		if len(values) == 1 {
			return values[0]
		}
		log.Fatalf("Entry %v is not a string or string array of size 1", s)
	}
	if str, ok := s.(string); ok {
		return str
	}
	log.Fatalf("Entry %v is not a string", s)
	return ""
}

// getInt casts the given interface (expected int) as int.
func getInt(s interface{}) int {
	if value, ok := s.(int); ok {
		return value
	}
	log.Fatalf("Entry %v is not an integer", s)
	return 0
}

// getBool casts the given interface (expected bool) as bool.
func getBool(s interface{}) bool {
	if value, ok := s.(bool); ok {
		return value
	}
	log.Fatalf("Entry %v is not a boolean", s)
	return false
}

// getInterfaceArray casts the given interface (expected interface array) as interface array.
func getInterfaceArray(s interface{}) []interface{} {
	if interfaceArray, ok := s.([]interface{}); ok {
		return interfaceArray
	}
	log.Fatalf("Entry %v is not an interface array", s)
	return nil
}

// getStringArray casts the given interface (expected string array) as string array.
func getStringArray(s interface{}) []string {
	interfaceArray := getInterfaceArray(s)
	strArray := make([]string, len(interfaceArray))
	for i := range interfaceArray {
		strArray[i] = getString(interfaceArray[i])
	}
	return strArray
}

// getMapSlice casts the given interface (expected MapSlice) as MapSlice.
func getMapSlice(m interface{}) yaml.MapSlice {
	if mm, ok := m.(yaml.MapSlice); ok {
		return mm
	}
	log.Fatalf("Entry %v is not a yaml.MapSlice", m)
	return nil
}

// Config generation functions.

// newbaseProwJobTemplateData returns a baseProwJobTemplateData type with its initial, default values.
func newbaseProwJobTemplateData(repo string) baseProwJobTemplateData {
	var data baseProwJobTemplateData
	data.Timeout = 50
	data.RepoName = strings.Replace(repo, "knative/", "", 1)
	data.RepoNameForJob = strings.Replace(repo, "/", "-", -1)
	data.GcsBucket = gcsBucket
	data.RepoURI = "github.com/" + repo
	data.CloneURI = fmt.Sprintf("\"https://%s.git\"", data.RepoURI)
	data.GcsLogDir = fmt.Sprintf("gs://%s/%s", gcsBucket, logsDir)
	data.GcsPresubmitLogDir = fmt.Sprintf("gs://%s/%s", gcsBucket, presubmitLogsDir)
	data.Year = time.Now().Year()
	data.PresubmitLogsDir = presubmitLogsDir
	data.LogsDir = logsDir
	data.ReleaseGcs = strings.Replace(repo, "knative/", "knative-releases/", 1)
	data.AlwaysRun = true
	data.Image = prowTestsDockerImage
	data.ServiceAccount = testAccount
	data.Command = ""
	data.Args = make([]string, 0)
	data.Volumes = make([]string, 0)
	data.VolumeMounts = make([]string, 0)
	data.Env = make([]string, 0)
	data.ExtraRefs = []string{"- org: knative", "  repo: " + data.RepoName, "  base_ref: master", "  clone_uri: " + data.CloneURI}
	return data
}

// newBaseTestgridTemplateData returns a testgridTemplateData type with its initial, default values.
func newBaseTestgridTemplateData(testGroupName string) baseTestgridTemplateData {
	var data baseTestgridTemplateData
	data.Year = time.Now().Year()
	data.TestGroupName = testGroupName
	return data
}

// General helpers.

// createCommand returns an array with the command to run and its arguments.
func createCommand(data baseProwJobTemplateData) []string {
	c := []string{data.Command}
	// Prefix the pre-command if present.
	if preCommand != "" {
		c = append([]string{preCommand}, c...)
	}
	return append(c, data.Args...)
}

// addEnvToJob adds the given key/pair environment variable to the job.
func addEnvToJob(data *baseProwJobTemplateData, key, value string) {
	// Value should always be string. Add quotes if we get a number
	if isNum(value) {
		value = "\"" + value + "\""
	}

	(*data).Env = append((*data).Env, []string{"- name: " + key, "  value: " + value}...)
}

// addVolumeToJob adds the given mount path as volume for the job.
func addVolumeToJob(data *baseProwJobTemplateData, mountPath, name string, isSecret bool) {
	(*data).VolumeMounts = append((*data).VolumeMounts, []string{"- name: " + name, "  mountPath: " + mountPath}...)
	if isSecret {
		(*data).VolumeMounts = append((*data).VolumeMounts, "  readOnly: true")
	}
	s := []string{"- name: " + name}
	if isSecret {
		s = append(s, []string{"  secret:", "    secretName: " + name}...)
	} else {
		s = append(s, "  emptyDir: {}")
	}
	(*data).Volumes = append((*data).Volumes, s...)
}

// configureServiceAccountForJob adds the necessary volumes for the service account for the job.
func configureServiceAccountForJob(data *baseProwJobTemplateData) {
	if data.ServiceAccount == "" {
		return
	}
	p := strings.Split(data.ServiceAccount, "/")
	if len(p) != 4 || p[0] != "" || p[1] != "etc" || p[3] != "service-account.json" {
		log.Fatalf("Service account path %q is expected to be \"/etc/<name>/service-account.json\"", data.ServiceAccount)
	}
	name := p[2]
	addVolumeToJob(data, "/etc/"+name, name, true)
}

// addExtraEnvVarsToJob adds any extra environment variables (defined on command-line) to a job.
func addExtraEnvVarsToJob(data *baseProwJobTemplateData) {
	for _, env := range extraEnvVars {
		pair := strings.Split(env, "=")
		if len(pair) != 2 {
			log.Fatalf("Environment variable %q is expected to be \"key=value\"", env)
		}
		addEnvToJob(data, pair[0], pair[1])
	}
}

// setupDockerInDockerForJob enables docker-in-docker for the given job.
func setupDockerInDockerForJob(data *baseProwJobTemplateData) {
	addVolumeToJob(data, "/docker-graph", "docker-graph", false)
	addEnvToJob(data, "DOCKER_IN_DOCKER_ENABLED", "\"true\"")
	(*data).SecurityContext = []string{"privileged: true"}
}

// Config parsers.

// parseBasicJobConfigOverrides updates the given baseProwJobTemplateData with any base option present in the given config.
func parseBasicJobConfigOverrides(data *baseProwJobTemplateData, config yaml.MapSlice) {
	for i, item := range config {
		switch item.Key {
		case "skip_branches":
			(*data).SkipBranches = getStringArray(item.Value)
		case "args":
			(*data).Args = getStringArray(item.Value)
		case "timeout":
			(*data).Timeout = getInt(item.Value)
		case "command":
			(*data).Command = getString(item.Value)
		case "needs-dind":
			if getBool(item.Value) {
				setupDockerInDockerForJob(data)
			}
		case "always_run":
			(*data).AlwaysRun = getBool(item.Value)
		case nil: // already processed
			continue
		default:
			log.Fatalf("Unknown entry %q for job", item.Key)
			continue
		}
		// Knock-out the item, signalling it was already parsed.
		config[i] = yaml.MapItem{}
	}
	// Override any values if provided by command-line flags.
	if timeoutOverride > 0 {
		(*data).Timeout = timeoutOverride
	}
}

// generatePresubmit generates all presubmit job configs for the given repo and configuration.
func generatePresubmit(title string, repoName string, presubmitConfig yaml.MapSlice) {
	var data presubmitJobTemplateData
	data.Base = newbaseProwJobTemplateData(repoName)
	data.Base.Command = presubmitScript
	data.Base.GoCoverageThreshold = 50
	jobTemplate := presubmitJob
	repoData := repositoryData{Name: repoName, EnableGoCoverage: false, GoCoverageThreshold: data.Base.GoCoverageThreshold}
	for i, item := range presubmitConfig {
		switch item.Key {
		case "build-tests", "unit-tests", "integration-tests":
			if !getBool(item.Value) {
				return
			}
			jobName := getString(item.Key)
			data.PresubmitJobName = data.Base.RepoNameForJob + "-" + jobName
			// Use default arguments if none given.
			if len(data.Base.Args) == 0 {
				data.Base.Args = []string{"--" + jobName}
			}
		case "go-coverage":
			if !getBool(item.Value) {
				return
			}
			jobTemplate = presubmitGoCoverageJob
			data.PresubmitJobName = data.Base.RepoNameForJob + "-go-coverage"
			data.Base.Image = coverageDockerImage
			data.Base.ServiceAccount = ""
			repoData.EnableGoCoverage = true
			addVolumeToJob(&data.Base, "/etc/covbot-token", "covbot-token", true)
		case "custom-test":
			data.PresubmitJobName = data.Base.RepoNameForJob + "-" + getString(item.Value)
		case "go-coverage-threshold":
			data.Base.GoCoverageThreshold = getInt(item.Value)
			repoData.GoCoverageThreshold = data.Base.GoCoverageThreshold
		default:
			continue
		}
		// Knock-out the item, signalling it was already parsed.
		presubmitConfig[i] = yaml.MapItem{}
	}
	parseBasicJobConfigOverrides(&data.Base, presubmitConfig)
	repositories = append(repositories, repoData)
	data.PresubmitCommand = createCommand(data.Base)
	data.PresubmitPullJobName = "pull-" + data.PresubmitJobName
	data.PresubmitPostJobName = "post-" + data.PresubmitJobName
	if data.Base.ServiceAccount != "" {
		addEnvToJob(&data.Base, "GOOGLE_APPLICATION_CREDENTIALS", data.Base.ServiceAccount)
		addEnvToJob(&data.Base, "E2E_CLUSTER_REGION", "us-central1")
	}
	addExtraEnvVarsToJob(&data.Base)
	configureServiceAccountForJob(&data.Base)
	executeJobTemplate("presubmit", jobTemplate, title, repoName, data.PresubmitPullJobName, true, data)
	// TODO(adrcunha): remove once the coverage-dev job isn't necessary anymore.
	// Generate config for pull-knative-serving-go-coverage-dev right after pull-knative-serving-go-coverage
	if data.PresubmitPullJobName == "pull-knative-serving-go-coverage" {
		data.PresubmitPullJobName += "-dev"
		data.Base.AlwaysRun = false
		data.Base.Image = strings.Replace(data.Base.Image, "coverage:latest", "coverage-dev:latest-dev", -1)
		template := strings.Replace(presubmitGoCoverageJob, "(all|", "(", 1)
		executeJobTemplate("presubmit", template, title, repoName, data.PresubmitPullJobName, true, data)
	}
}

// generatePeriodic generates all periodic job configs for the given repo and configuration.
func generatePeriodic(title string, repoName string, periodicConfig yaml.MapSlice) {
	var data periodicJobTemplateData
	data.Base = newbaseProwJobTemplateData(repoName)
	jobNameSuffix := ""
	jobTemplate := periodicTestJob
	jobType := ""

	for i, item := range periodicConfig {
		switch item.Key {
		case "continuous":
			if !getBool(item.Value) {
				return
			}
			jobType = getString(item.Key)
			jobNameSuffix = "continuous"
			// Use default command and arguments if none given.
			if data.Base.Command == "" {
				data.Base.Command = presubmitScript
			}
			if len(data.Base.Args) == 0 {
				data.Base.Args = allPresubmitTests
			}
		case "nightly":
			if !getBool(item.Value) {
				return
			}
			jobType = getString(item.Key)
			jobNameSuffix = "nightly-release"
			data.Base.ServiceAccount = nightlyAccount
			data.Base.Command = releaseScript
			data.Base.Args = releaseNightly
			data.Base.Timeout = 90
		case "branch-ci":
			if !getBool(item.Value) {
				return
			}
			jobType = getString(item.Key)
			jobNameSuffix = "continuous"
			data.Base.Command = releaseScript
			data.Base.Args = releaseLocal
			setupDockerInDockerForJob(&data.Base)
			// TODO(adrcunha): Consider reducing the timeout in the future.
			data.Base.Timeout = 180
		case "dot-release", "auto-release":
			if !getBool(item.Value) {
				return
			}
			jobType = getString(item.Key)
			jobNameSuffix = getString(item.Key)
			data.Base.ServiceAccount = releaseAccount
			data.Base.Command = releaseScript
			data.Base.Args = []string{
				"--" + jobNameSuffix,
				"--release-gcs " + data.Base.ReleaseGcs,
				"--release-gcr gcr.io/knative-releases",
				"--github-token /etc/hub-token/token"}
			addVolumeToJob(&data.Base, "/etc/hub-token", "hub-token", true)
			data.Base.Timeout = 90
		case "performance", "performance-mesh":
			if !getBool(item.Value) {
				return
			}
			jobType = getString(item.Key)
			jobNameSuffix = getString(item.Key)
			data.Base.Command = performanceScript
			// We need a larger cluster of at least 16 nodes for perf tests
			addEnvToJob(&data.Base, "E2E_MIN_CLUSTER_NODES", "16")
			addEnvToJob(&data.Base, "E2E_MAX_CLUSTER_NODES", "16")
			data.Base.Timeout = 120
		case "latency":
			if !getBool(item.Value) {
				return
			}
			jobType = getString(item.Key)
			jobTemplate = periodicCustomJob
			jobNameSuffix = "latency"
			data.Base.Image = "gcr.io/knative-tests/test-infra/metrics:latest"
			data.Base.Command = "/metrics"
			data.Base.Args = []string{
				fmt.Sprintf("--source-directory=ci-%s-continuous", data.Base.RepoNameForJob),
				"--artifacts-dir=$(ARTIFACTS)",
				"--service-account=" + data.Base.ServiceAccount}
		case "custom-job":
			jobType = getString(item.Key)
			jobNameSuffix = getString(item.Value)
		case "cron":
			data.CronString = getString(item.Value)
		case "release":
			version := getString(item.Value)
			jobNameSuffix = version + "-" + jobNameSuffix
			data.Base.RepoBranch = "release-" + version
		case "webhook-apicoverage":
			if !getBool(item.Value) {
				return
			}
			jobNameSuffix = "webhook-apicoverage"
			data.Base.Command = webhookAPICoverageScript
			addEnvToJob(&data.Base, "SYSTEM_NAMESPACE", data.Base.RepoNameForJob)
		default:
			continue
		}
		// Knock-out the item, signalling it was already parsed.
		periodicConfig[i] = yaml.MapItem{}
	}

	parseBasicJobConfigOverrides(&data.Base, periodicConfig)
	data.PeriodicJobName = fmt.Sprintf("ci-%s", data.Base.RepoNameForJob)
	if jobNameSuffix != "" {
		data.PeriodicJobName += "-" + jobNameSuffix
	}
	// Ensure required data exist.
	if data.CronString == "" {
		log.Fatalf("Job %q is missing cron string", data.PeriodicJobName)
	}
	if len(data.Base.Args) == 0 && data.Base.Command == "" {
		log.Fatalf("Job %q is missing command", data.PeriodicJobName)
	}
	if jobType == "branch-ci" && data.Base.RepoBranch == "" {
		log.Fatalf("%q jobs are intended to be used on release branches", jobType)
	}
	// Generate config itself.
	data.PeriodicCommand = createCommand(data.Base)
	if data.Base.ServiceAccount != "" {
		addEnvToJob(&data.Base, "GOOGLE_APPLICATION_CREDENTIALS", data.Base.ServiceAccount)
		addEnvToJob(&data.Base, "E2E_CLUSTER_REGION", "us-central1")
	}
	if data.Base.RepoBranch != "" {
		// If it's a release version, add env var PULL_BASE_REF as ref name of the base branch.
		// TODO(Fredy-Z): this serves as a workaround, see https://github.com/knative/test-infra/issues/780.
		addEnvToJob(&data.Base, "PULL_BASE_REF", data.Base.RepoBranch)
	}
	addExtraEnvVarsToJob(&data.Base)
	configureServiceAccountForJob(&data.Base)
	executeJobTemplate("periodic", jobTemplate, title, repoName, data.PeriodicJobName, false, data)
}

// generateCleanupPeriodicJob generates the cleanup job config.
func generateCleanupPeriodicJob() {
	var data periodicJobTemplateData
	data.Base = newbaseProwJobTemplateData("knative/test-infra")
	data.PeriodicJobName = "ci-knative-cleanup"
	data.CronString = cleanupPeriodicJobCron
	data.Base.DecorationConfig = []string{"timeout: 86400000000000"} // 24 hours
	data.Base.Command = cleanupScript
	data.Base.Args = []string{
		"--project-resource-yaml ci/prow/boskos/resources.yaml",
		"--days-to-keep-images 30",
		"--hours-to-keep-clusters 24",
		"--service-account " + data.Base.ServiceAccount,
		"--artifacts $(ARTIFACTS)"}
	addExtraEnvVarsToJob(&data.Base)
	configureServiceAccountForJob(&data.Base)
	executeJobTemplate("periodic cleanup", periodicCustomJob, "presubmits", "", data.PeriodicJobName, false, data)
}

// generateFlakytoolPeriodicJob generates the cleanup job config.
func generateFlakytoolPeriodicJob() {
	var data periodicJobTemplateData
	data.Base = newbaseProwJobTemplateData("knative/test-infra")
	data.Base.Image = flakesreporterDockerImage
	data.PeriodicJobName = "ci-knative-flakes-reporter"
	data.CronString = flakesReporterPeriodicJobCron
	data.Base.Command = "/flaky-test-reporter"
	data.Base.Args = []string{
		"--service-account=" + data.Base.ServiceAccount,
		"--github-account=/etc/flaky-test-reporter-github-token/token",
		"--slack-account=/etc/flaky-test-reporter-slack-token/token"}
	addExtraEnvVarsToJob(&data.Base)
	configureServiceAccountForJob(&data.Base)
	addVolumeToJob(&data.Base, "/etc/flaky-test-reporter-github-token", "flaky-test-reporter-github-token", true)
	addVolumeToJob(&data.Base, "/etc/flaky-test-reporter-slack-token", "flaky-test-reporter-slack-token", true)
	executeJobTemplate("periodic flakesreporter", periodicCustomJob, "presubmits", "", data.PeriodicJobName, false, data)
}

// generateBackupPeriodicJob generates the backup job config.
func generateBackupPeriodicJob() {
	var data periodicJobTemplateData
	data.Base = newbaseProwJobTemplateData("none/unused")
	data.Base.ServiceAccount = "/etc/backup-account/service-account.json"
	data.Base.Image = "gcr.io/knative-tests/test-infra/backups:latest"
	data.PeriodicJobName = "ci-knative-backup-artifacts"
	data.CronString = backupPeriodicJobCron
	data.Base.Command = "/backup.sh"
	data.Base.Args = []string{data.Base.ServiceAccount}
	data.Base.ExtraRefs = []string{} // no repo clone required
	addExtraEnvVarsToJob(&data.Base)
	configureServiceAccountForJob(&data.Base)
	executeJobTemplate("periodic backup", periodicCustomJob, "presubmits", "", data.PeriodicJobName, false, data)
}

// generateGoCoveragePeriodic generates the go coverage periodic job config for the given repo (configuration is ignored).
func generateGoCoveragePeriodic(title string, repoName string, _ yaml.MapSlice) {
	for i, repo := range repositories {
		if repoName != repo.Name || !repo.EnableGoCoverage {
			continue
		}
		repositories[i].Processed = true
		var data periodicJobTemplateData
		data.Base = newbaseProwJobTemplateData(repoName)
		data.Base.Image = coverageDockerImage
		data.PeriodicJobName = fmt.Sprintf("ci-%s-go-coverage", data.Base.RepoNameForJob)
		data.CronString = goCoveragePeriodicJobCron
		data.Base.GoCoverageThreshold = repo.GoCoverageThreshold
		data.Base.Command = "/coverage"
		data.Base.Args = []string{
			"--artifacts=$(ARTIFACTS)",
			fmt.Sprintf("--cov-threshold-percentage=%d", data.Base.GoCoverageThreshold)}
		data.Base.ServiceAccount = ""
		addExtraEnvVarsToJob(&data.Base)
		configureServiceAccountForJob(&data.Base)
		executeJobTemplate("periodic go coverage", periodicCustomJob, title, repoName, data.PeriodicJobName, false, data)
		return
	}
}

// generateGoCoveragePostsubmit generates the go coverage postsubmit job config for the given repo.
func generateGoCoveragePostsubmit(title, repoName string, _ yaml.MapSlice) {
	var data postsubmitJobTemplateData
	data.Base = newbaseProwJobTemplateData(repoName)
	data.Base.Image = coverageDockerImage
	data.PostsubmitJobName = fmt.Sprintf("post-%s-go-coverage", data.Base.RepoNameForJob)
	addExtraEnvVarsToJob(&data.Base)
	configureServiceAccountForJob(&data.Base)
	executeJobTemplate("postsubmit go coverage", goCoveragePostsubmitJob, "postsubmits", repoName, data.PostsubmitJobName, true, data)
	// TODO(adrcunha): remove once the coverage-dev job isn't necessary anymore.
	// Generate config for post-knative-serving-go-coverage-dev right after post-knative-serving-go-coverage
	if data.PostsubmitJobName == "post-knative-serving-go-coverage" {
		data.PostsubmitJobName += "-dev"
		data.Base.Image = strings.Replace(data.Base.Image, "coverage:latest", "coverage-dev:latest-dev", -1)
		executeJobTemplate("presubmit", goCoveragePostsubmitJob, "postsubmits", repoName, data.PostsubmitJobName, false, data)
	}
}

// parseSection generate the configs from a given section of the input yaml file.
func parseSection(config yaml.MapSlice, title string, generate sectionGenerator, finalize sectionGenerator) {
	for _, section := range config {
		if section.Key != title {
			continue
		}
		for _, repo := range getMapSlice(section.Value) {
			repoName := getString(repo.Key)
			for _, jobConfig := range getInterfaceArray(repo.Value) {
				generate(title, repoName, getMapSlice(jobConfig))
			}
			if finalize != nil {
				finalize(title, repoName, nil)
			}
		}
	}
}

// generateOtherJobConfigs generates job config with the generator if new job is required for it.
func generateOtherJobConfigs(title string, newJobNeeded newJobNeeded, generate sectionGenerator) {
	for i := range repositories { // Keep order for predictable output.
		if !newJobNeeded(repositories[i]) {
			continue
		}
		generate(title, repositories[i].Name, nil)
	}
}

// Template helpers.

// gitHubRepo returns the correct reference for the GitHub repository.
func gitHubRepo(data baseProwJobTemplateData) string {
	if repositoryOverride != "" {
		return repositoryOverride
	}
	s := data.RepoURI
	if data.RepoBranch != "" {
		s += "=" + data.RepoBranch
	}
	return s
}

// isNum checks if the given string is a valid number
func isNum(s string) bool {
	_, err := strconv.ParseFloat(s, 64)
	return err == nil
}

// quote returns the given string quoted if it's not a number, or not a key/value pair, or already quoted.
func quote(s string) string {
	if isNum(s) {
		return s
	}
	if strings.Contains(s, "\"") || strings.Contains(s, ": ") || strings.HasSuffix(s, ":") {
		return s
	}
	return "\"" + s + "\""
}

// indentBase is a helper function which returns the given array indented.
func indentBase(indentation int, prefix string, indentFirstLine bool, array []string) string {
	s := ""
	if len(array) == 0 {
		return s
	}
	indent := strings.Repeat(" ", indentation)
	for i := 0; i < len(array); i++ {
		if i > 0 || indentFirstLine {
			s += indent
		}
		s += prefix + quote(array[i]) + "\n"
	}
	return s
}

// indentArray returns the given array indented, prefixed by "-".
func indentArray(indentation int, array []string) string {
	return indentBase(indentation, "- ", false, array)
}

// indentKeys returns the given array of key/value pairs indented.
func indentKeys(indentation int, array []string) string {
	return indentBase(indentation, "", false, array)
}

// indentSectionBase is a helper function which returns the given array of key/value pairs indented inside a section.
func indentSectionBase(indentation int, title string, prefix string, array []string) string {
	keys := indentBase(indentation, prefix, true, array)
	if keys == "" {
		return keys
	}
	return title + ":\n" + keys
}

// indentArraySection returns the given array indented inside a section.
func indentArraySection(indentation int, title string, array []string) string {
	return indentSectionBase(indentation, title, "- ", array)
}

// indentSection returns the given array of key/value pairs indented inside a section.
func indentSection(indentation int, title string, array []string) string {
	return indentSectionBase(indentation, title, "", array)
}

// indentMap returns the given map indented, with each key/value separated by ": "
func indentMap(indentation int, mp map[string]string) string {
	// Extract map keys to keep order consistent.
	keys := make([]string, 0, len(mp))
	for key := range mp {
		keys = append(keys, key)
	}
	sort.Strings(keys)
	arr := make([]string, len(mp))
	for i := 0; i < len(mp); i++ {
		arr[i] = keys[i] + ": " + quote(mp[keys[i]])
	}
	return indentBase(indentation, "", false, arr)
}

// outputConfig outputs the given line, if not empty, to stdout.
func outputConfig(line string) {
	s := strings.TrimSpace(line)
	if s != "" {
		fmt.Fprintln(output, line)
	}
}

// strExists checks if the given string exists in the array
func strExists(arr []string, str string) bool {
	for _, s := range arr {
		if str == s {
			return true
		}
	}
	return false
}

// executeTemplate outputs the given job template with the given data, respecting any filtering.
func executeJobTemplate(name, templ, title, repoName, jobName string, groupByRepo bool, data interface{}) {
	if jobNameFilter != "" && jobNameFilter != jobName {
		return
	}
	if !sectionMap[title] {
		outputConfig(title + ":")
		sectionMap[title] = true
	}
	if groupByRepo {
		if !sectionMap[title+repoName] {
			outputConfig(baseIndent + repoName + ":")
			sectionMap[title+repoName] = true
		}
	}
	executeTemplate(name, templ, data)
}

// executeTemplate outputs the given template with the given data.
func executeTemplate(name, templ string, data interface{}) {
	var res bytes.Buffer
	funcMap := template.FuncMap{
		"indent_section":       indentSection,
		"indent_array_section": indentArraySection,
		"indent_array":         indentArray,
		"indent_keys":          indentKeys,
		"indent_map":           indentMap,
		"repo":                 gitHubRepo,
	}
	t := template.Must(template.New(name).Funcs(funcMap).Delims("[[", "]]").Parse(templ))
	if err := t.Execute(&res, data); err != nil {
		log.Fatalf("Error in template %s: %v", name, err)
	}
	for _, line := range strings.Split(res.String(), "\n") {
		outputConfig(line)
	}
}

// Multi-value flag parser.

func (a *stringArrayFlag) String() string {
	return strings.Join(*a, ", ")
}

func (a *stringArrayFlag) Set(value string) error {
	*a = append(*a, value)
	return nil
}

// parseJob gets the job data from the original yaml data, now the jobName can be "presubmits" or "periodic"
func parseJob(config yaml.MapSlice, jobName string) yaml.MapSlice {
	for _, section := range config {
		if section.Key == jobName {
			return getMapSlice(section.Value)
		}
	}

	log.Fatalf("The metadata misses %s configuration, cannot continue.", jobName)
	return nil
}

// parseGoCoverageMap constructs a map, indicating which repo is enabled for go coverage check
func parseGoCoverageMap(presubmitJob yaml.MapSlice) map[string]bool {
	goCoverageMap := make(map[string]bool)
	for _, repo := range presubmitJob {
		repoName := strings.Split(getString(repo.Key), "/")[1]
		goCoverageMap[repoName] = false
		for _, jobConfig := range getInterfaceArray(repo.Value) {
			for _, item := range getMapSlice(jobConfig) {
				if item.Key == "go-coverage" {
					goCoverageMap[repoName] = getBool(item.Value)
					break
				}
			}
		}
	}

	return goCoverageMap
}

// collectMetaData collects the meta data from the original yaml data, which can be then used for building the test groups and dashboards config
func collectMetaData(periodicJob yaml.MapSlice) {
	for _, repo := range periodicJob {
		rawName := getString(repo.Key)
		projName := strings.Split(rawName, "/")[0]
		repoName := strings.Split(rawName, "/")[1]
		jobDetailMap := addProjAndRepoIfNeed(projName, repoName)

		// parse job configs
		for _, conf := range getInterfaceArray(repo.Value) {
			jobDetailMap = metaData[projName]
			jobConfig := getMapSlice(conf)
			enabled := false
			jobName := ""
			releaseVersion := ""
			for _, item := range jobConfig {
				switch item.Key {
				case "continuous", "dot-release", "auto-release", "performance", "performance-mesh", "latency", "nightly":
					if getBool(item.Value) {
						enabled = true
						jobName = getString(item.Key)
					}
				case "branch-ci":
					enabled = getBool(item.Value)
					jobName = "continuous"
				case "release":
					releaseVersion = getString(item.Value)
				case "custom-job":
					enabled = true
					jobName = getString(item.Value)
				default:
					// continue here since we do not need to care about other entries, like cron, command, etc.
					continue
				}
			}
			// add job types for the corresponding repos, if needed
			if enabled {
				// if it's a job for a release branch
				if releaseVersion != "" {
					releaseProjName := fmt.Sprintf("%s-%s", projName, releaseVersion)
					jobDetailMap = addProjAndRepoIfNeed(releaseProjName, repoName)
				}
				newJobTypes := append(jobDetailMap[repoName], jobName)
				jobDetailMap[repoName] = newJobTypes
			}
		}
		addTestCoverageJobIfNeeded(&jobDetailMap, repoName)
	}

	// add test coverage jobs for the repos that haven't been handled
	addRemainingTestCoverageJobs()
}

// addProjAndRepoIfNeed adds the project and repo if they are new in the metaData map, then return the jobDetailMap
func addProjAndRepoIfNeed(projName string, repoName string) map[string][]string {
	// add project in the metaData
	if _, exists := metaData[projName]; !exists {
		metaData[projName] = make(map[string][]string)
		if !strExists(projNames, projName) {
			projNames = append(projNames, projName)
		}
	}

	// add repo in the project
	jobDetailMap := metaData[projName]
	if _, exists := jobDetailMap[repoName]; !exists {
		if !strExists(repoNames, repoName) {
			repoNames = append(repoNames, repoName)
		}
		jobDetailMap[repoName] = make([]string, 0)
	}
	return jobDetailMap
}

// addTestCoverageJobIfNeeded adds test-coverage job for the repo if it has go coverage check
func addTestCoverageJobIfNeeded(jobDetailMap *map[string][]string, repoName string) {
	if goCoverageMap[repoName] {
		newJobTypes := append((*jobDetailMap)[repoName], "test-coverage")
		(*jobDetailMap)[repoName] = newJobTypes
		// delete this repoName from the goCoverageMap to avoid it being processed again when we
		// call the function addRemainingTestCoverageJobs
		delete(goCoverageMap, repoName)
	}
}

// addRemainingTestCoverageJobs adds test-coverage jobs for the repos that haven't been processed.
func addRemainingTestCoverageJobs() {
	// handle repos that only have go coverage
	for repoName, hasGoCoverage := range goCoverageMap {
		if hasGoCoverage {
			jobDetailMap := addProjAndRepoIfNeed(projNames[0], repoName)
			jobDetailMap[repoName] = []string{"test-coverage"}
		}
	}
}

// generateSection generates the configs for the section with the given generator
func generateSection(sectionName string, generator testgridEntityGenerator, skipReleasedProj bool) {
	outputConfig(sectionName + ":")
	for _, projName := range projNames {
		// Do not handle the project if it is released and we want to skip it.
		if skipReleasedProj && isReleased(projName) {
			continue
		}
		repos := metaData[projName]
		for _, repoName := range repoNames {
			if _, exists := repos[repoName]; exists {
				jobNames := repos[repoName]
				repoName = buildProjRepoStr(projName, repoName)
				generator(repoName, jobNames)
			}
		}
	}
}

// generateTestGroup generates the test group configuration
func generateTestGroup(repoName string, jobNames []string) {
	for _, jobName := range jobNames {
		testGroupName := getTestGroupName(repoName, jobName)
		gcsLogDir := fmt.Sprintf("%s/%s/%s", gcsBucket, logsDir, testGroupName)
		extras := make(map[string]string)
		switch jobName {
		case "continuous", "dot-release", "auto-release", "performance", "performance-mesh", "latency", "playground", "nightly":
			isDailyBranch := regexp.MustCompile(`-[0-9\.]+-continuous`).FindString(testGroupName) != ""
			if !isDailyBranch && (jobName == "continuous" || jobName == "auto-release") {
				// TODO(Fredy-Z): this value should be derived from the cron string
				extras["alert_stale_results_hours"] = "3"
				if jobName == "continuous" {
					// For continuous flows, alert after 3 failures due to flakiness
					extras["num_failures_to_alert"] = "3"
				}
			}
			if jobName == "playground" || jobName == "dot-release" {
				// TODO(Fredy-Z): this value should be derived from the cron string
				extras["alert_stale_results_hours"] = "170" // 1 week + 2h
			}
			if jobName == "latency" {
				extras["short_text_metric"] = "latency"
			}
			if jobName == "performance" || jobName == "performance-mesh" {
				extras["short_text_metric"] = "perf_latency"
			}
		case "test-coverage":
			gcsLogDir = fmt.Sprintf("%s/%s/ci-%s-%s", gcsBucket, logsDir, repoName, "go-coverage")
			extras["short_text_metric"] = "coverage"
			// Do not alert on coverage failures (i.e., coverage below threshold)
			extras["num_failures_to_alert"] = "9999"
		case "istio-1.0.7-mesh", "istio-1.0.7-no-mesh", "istio-1.1.2-mesh", "istio-1.1.2-no-mesh":
			extras["alert_stale_results_hours"] = "3"
			extras["num_failures_to_alert"] = "3"
		default:
			log.Fatalf("Unknown jobName for generateTestGroup: %s", jobName)
		}
		executeTestGroupTemplate(testGroupName, gcsLogDir, extras)
	}
}

// executeTestGroupTemplate outputs the given test group config template with the given data
func executeTestGroupTemplate(testGroupName string, gcsLogDir string, extras map[string]string) {
	var data testGroupTemplateData
	data.Base.TestGroupName = testGroupName
	data.GcsLogDir = gcsLogDir
	data.Extras = extras
	executeTemplate("test group", testGroupTemplate, data)
}

// generateDashboard generates the dashboard configuration
func generateDashboard(repoName string, jobNames []string) {
	outputConfig("- name: " + repoName + "\n" + baseIndent + "dashboard_tab:")
	noExtras := make(map[string]string)
	for _, jobName := range jobNames {
		testGroupName := getTestGroupName(repoName, jobName)
		switch jobName {
		case "continuous":
			executeDashboardTabTemplate("continuous", testGroupName, testgridTabSortByName, noExtras)
			// This is a special case for knative/serving, as conformance-tests tab is just a filtered view of the continuous tab.
			if repoName == "knative-serving" {
				executeDashboardTabTemplate("conformance-tests", testGroupName, "include-filter-by-regex=test/conformance\\\\.&sort-by-name=", noExtras)
			}
		case "dot-release", "auto-release", "performance", "performance-mesh", "latency", "playground":
			extras := make(map[string]string)
			baseOptions := testgridTabSortByName
			if jobName == "performance" || jobName == "performance-mesh" {
				baseOptions = testgridTabGroupByTarget
			}
			if jobName == "latency" {
				baseOptions = testgridTabGroupByDir
				extras["description"] = "95% latency in ms"
			}
			executeDashboardTabTemplate(jobName, testGroupName, baseOptions, extras)
		case "nightly":
			executeDashboardTabTemplate("nightly", testGroupName, testgridTabSortByName, noExtras)
		case "test-coverage":
			executeDashboardTabTemplate("coverage", testGroupName, testgridTabGroupByDir, noExtras)
		case "istio-1.0.7-mesh", "istio-1.0.7-no-mesh", "istio-1.1.2-mesh", "istio-1.1.2-no-mesh":
			executeDashboardTabTemplate(jobName, testGroupName, testgridTabSortByName, noExtras)
		default:
			log.Fatalf("Unknown job name %q", jobName)
		}
	}
}

// executeTestGroupTemplate outputs the given dashboard tab config template with the given data
func executeDashboardTabTemplate(dashboardTabName string, testGroupName string, baseOptions string, extras map[string]string) {
	var data dashboardTabTemplateData
	data.Name = dashboardTabName
	data.Base.TestGroupName = testGroupName
	data.BaseOptions = baseOptions
	data.Extras = extras
	executeTemplate("dashboard tab", dashboardTabTemplate, data)
}

// getTestGroupName get the testGroupName from the given repoName and jobName
func getTestGroupName(repoName string, jobName string) string {
	switch jobName {
	case "continuous", "dot-release", "auto-release", "performance", "performance-mesh", "latency", "playground":
		return fmt.Sprintf("ci-%s-%s", repoName, jobName)
	case "nightly":
		return fmt.Sprintf("ci-%s-%s-release", repoName, jobName)
	case "test-coverage":
		return fmt.Sprintf("pull-%s-%s", repoName, jobName)
	case "istio-1.0.7-mesh", "istio-1.0.7-no-mesh", "istio-1.1.2-mesh", "istio-1.1.2-no-mesh":
		return fmt.Sprintf("ci-%s-%s", repoName, jobName)
	}
	log.Fatalf("Unknown jobName for getTestGroupName: %s", jobName)
	return ""
}

// buildProjRepoStr builds the projRepoStr used in the config file with projName and repoName
func buildProjRepoStr(projName string, repoName string) string {
	projVersion := ""
	if strings.Contains(projName, "-") {
		projNameAndVersion := strings.Split(projName, "-")
		projName = projNameAndVersion[0]
		projVersion = projNameAndVersion[1]
	}
	projRepoStr := repoName
	if projVersion != "" {
		projRepoStr += ("-" + projVersion)
	}
	projRepoStr = projName + "-" + projRepoStr

	return projRepoStr
}

func generateDashboardsForReleases() {
	for _, projName := range projNames {
		// Do not handle the project if it is not released.
		if !isReleased(projName) {
			continue
		}
		repos := metaData[projName]
		outputConfig("- name: " + projName + "\n" + baseIndent + "dashboard_tab:")
		noExtras := make(map[string]string)
		for _, repoName := range repoNames {
			if _, exists := repos[repoName]; exists {
				testGroupName := getTestGroupName(buildProjRepoStr(projName, repoName), "continuous")
				executeDashboardTabTemplate(repoName, testGroupName, testgridTabSortByName, noExtras)
			}
		}
	}
}

// generateDashboardGroups generates the dashboard groups configuration
func generateDashboardGroups() {
	outputConfig("dashboard_groups:")
	for _, projName := range projNames {
		// there is only one dashboard for each released project, so we do not need to group them
		if isReleased(projName) {
			continue
		}

		dashboardRepoNames := make([]string, 0)
		repos := metaData[projName]
		for _, repoName := range repoNames {
			if _, exists := repos[repoName]; exists {
				dashboardRepoNames = append(dashboardRepoNames, buildProjRepoStr(projName, repoName))
			}
		}
		executeDashboardGroupTemplate(projName, dashboardRepoNames)
	}
}

// executeDashboardGroupTemplate outputs the given dashboard group config template with the given data
func executeDashboardGroupTemplate(dashboardGroupName string, dashboardRepoNames []string) {
	var data dashboardGroupTemplateData
	data.Name = dashboardGroupName
	data.RepoNames = dashboardRepoNames
	executeTemplate("dashboard group", dashboardGroupTemplate, data)
}

// isReleased returns true for project name that has version
func isReleased(projName string) bool {
	return regexp.MustCompile(`.+-[0-9\.]+$`).FindString(projName) != ""
}

// setOutput set the given file as the output target, then all the output will be written to this file
func setOutput(fileName string) {
	configFile, err := os.OpenFile(fileName, os.O_RDWR|os.O_CREATE, 0666)
	if err != nil {
		log.Fatalf("Cannot create the configuration file %q: %v", fileName, err)
	}
	configFile.Truncate(0)
	configFile.Seek(0, 0)
	output = configFile
}

// main is the script entry point.
func main() {
	// Parse flags and sanity check them.
	prowConfigOutput := ""
	testgridConfigOutput := ""
	var generateProwConfig = flag.Bool("generate-prow-config", true, "Whether to generate the prow configuration file from the template")
	flag.StringVar(&prowConfigOutput, "prow-config-output", "", "The destination for the prow config output, default to be stdout")
	var generateTestgridConfig = flag.Bool("generate-testgrid-config", true, "Whether to generate the testgrid config from the template file")
	flag.StringVar(&testgridConfigOutput, "testgrid-config-output", "", "The destination for the testgrid config output, default to be stdout")

	var includeConfig = flag.Bool("include-config", true, "Whether to include general configuration (e.g., plank) in the generated config")
	flag.StringVar(&gcsBucket, "gcs-bucket", "knative-prow", "GCS bucket to upload the logs to")
	flag.StringVar(&logsDir, "logs-dir", "logs", "Path in the GCS bucket to upload logs of periodic and post-submit jobs")
	flag.StringVar(&presubmitLogsDir, "presubmit-logs-dir", "pr-logs", "Path in the GCS bucket to upload logs of pre-submit jobs")
	flag.StringVar(&testAccount, "test-account", "/etc/test-account/service-account.json", "Path to the service account JSON for test jobs")
	flag.StringVar(&nightlyAccount, "nightly-account", "/etc/nightly-account/service-account.json", "Path to the service account JSON for nightly release jobs")
	flag.StringVar(&releaseAccount, "release-account", "/etc/release-account/service-account.json", "Path to the service account JSON for release jobs")
	flag.StringVar(&flakesreporterDockerImage, "flaky-test-reporter-docker", "gcr.io/knative-tests/test-infra/flaky-test-reporter:latest", "Docker image for flaky test reporting tool")
	flag.StringVar(&coverageDockerImage, "coverage-docker", "gcr.io/knative-tests/test-infra/coverage:latest", "Docker image for coverage tool")
	flag.StringVar(&prowTestsDockerImage, "prow-tests-docker", "gcr.io/knative-tests/test-infra/prow-tests:stable", "prow-tests docker image")
	flag.StringVar(&presubmitScript, "presubmit-script", "./test/presubmit-tests.sh", "Executable for running presubmit tests")
	flag.StringVar(&releaseScript, "release-script", "./hack/release.sh", "Executable for creating releases")
	flag.StringVar(&performanceScript, "performance-script", "./test/performance-tests.sh", "Executable for running performance tests")
	flag.StringVar(&webhookAPICoverageScript, "webhookAPICoverageScript", "./test/apicoverage.sh", "Executable for running webhook apicoverage tool")
	flag.StringVar(&cleanupScript, "cleanup-script", "./tools/cleanup/cleanup.sh", "Executable for running the cleanup tasks")
	flag.StringVar(&repositoryOverride, "repo-override", "", "Repository path (github.com/foo/bar[=branch]) to use instead for a job")
	flag.IntVar(&timeoutOverride, "timeout-override", 0, "Timeout (in minutes) to use instead for a job")
	flag.StringVar(&jobNameFilter, "job-filter", "", "Generate only this job, instead of all jobs")
	flag.StringVar(&preCommand, "pre-command", "", "Executable for running instead of the real command of a job")
	flag.Var(&extraEnvVars, "extra-env", "Extra environment variables (key=value) to add to a job")
	flag.Parse()
	if len(flag.Args()) != 1 {
		log.Fatal("Pass the config file as parameter")
	}
	// We use MapSlice instead of maps to keep key order and create predictable output.
	config := yaml.MapSlice{}

	// Read input config.
	name := flag.Arg(0)
	content, err := ioutil.ReadFile(name)
	if err != nil {
		log.Fatalf("Cannot read file %q: %v", name, err)
	}
	if err = yaml.Unmarshal(content, &config); err != nil {
		log.Fatalf("Cannot parse config %q: %v", name, err)
	}

	// Generate Prow config.
	if *generateProwConfig {
		output = os.Stdout
		if prowConfigOutput != "" {
			setOutput(prowConfigOutput)
		}
		repositories = make([]repositoryData, 0)
		sectionMap = make(map[string]bool)
		if *includeConfig {
			executeTemplate("general config", generalProwConfig, newbaseProwJobTemplateData(""))
		}
		parseSection(config, "presubmits", generatePresubmit, nil)
		parseSection(config, "periodics", generatePeriodic, generateGoCoveragePeriodic)
		generateOtherJobConfigs("periodics", func(repo repositoryData) bool {
			return !repo.Processed && repo.EnableGoCoverage
		}, generateGoCoveragePeriodic)
		generateCleanupPeriodicJob()
		generateFlakytoolPeriodicJob()
		generateBackupPeriodicJob()
		generateOtherJobConfigs("postsubmits", func(repo repositoryData) bool {
			return repo.EnableGoCoverage
		}, generateGoCoveragePostsubmit)
	}

	// config object is modified when we generate prow config, so we'll need to reload it here
	if err = yaml.Unmarshal(content, &config); err != nil {
		log.Fatalf("Cannot parse config %q: %v", name, err)
	}
	// Generate Testgrid config.
	if *generateTestgridConfig {
		output = os.Stdout
		if testgridConfigOutput != "" {
			setOutput(testgridConfigOutput)
		}

		if *includeConfig {
			executeTemplate("general config", generalTestgridConfig, newBaseTestgridTemplateData(""))
		}

		presubmitJobData := parseJob(config, "presubmits")
		goCoverageMap = parseGoCoverageMap(presubmitJobData)

		periodicJobData := parseJob(config, "periodics")
		collectMetaData(periodicJobData)

		generateSection("test_groups", generateTestGroup, false)
		generateSection("dashboards", generateDashboard, true)
		generateDashboardsForReleases()
		generateDashboardGroups()
	}
}
